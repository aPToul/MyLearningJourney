{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Enter an interactive TensorFlow Session.\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    \n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9116\n"
     ]
    }
   ],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close the Session when we're done.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from random import choice, shuffle\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TFKMeansCluster(vectors, noofclusters):\n",
    "    \"\"\"\n",
    "    K-Means Clustering using TensorFlow.\n",
    "    'vectors' should be a n*k 2-D NumPy array, where n is the number\n",
    "    of vectors of dimensionality k.\n",
    "    'noofclusters' should be an integer.\n",
    "    \"\"\"\n",
    " \n",
    "    noofclusters = int(noofclusters)\n",
    "    assert noofclusters < len(vectors)\n",
    " \n",
    "    #Find out the dimensionality\n",
    "    dim = len(vectors[0])\n",
    " \n",
    "    #Will help select random centroids from among the available vectors\n",
    "    vector_indices = list(range(len(vectors)))\n",
    "    shuffle(vector_indices)\n",
    " \n",
    "    #GRAPH OF COMPUTATION\n",
    "    #We initialize a new graph and set it as the default during each run\n",
    "    #of this algorithm. This ensures that as this function is called\n",
    "    #multiple times, the default graph doesn't keep getting crowded with\n",
    "    #unused ops and Variables from previous function calls.\n",
    " \n",
    "    graph = tf.Graph()\n",
    " \n",
    "    with graph.as_default():\n",
    " \n",
    "        #SESSION OF COMPUTATION\n",
    " \n",
    "        sess = tf.Session()\n",
    " \n",
    "        ##CONSTRUCTING THE ELEMENTS OF COMPUTATION\n",
    " \n",
    "        ##First lets ensure we have a Variable vector for each centroid,\n",
    "        ##initialized to one of the vectors from the available data points\n",
    "        centroids = [tf.Variable((vectors[vector_indices[i]]))\n",
    "                     for i in range(noofclusters)]\n",
    "        ##These nodes will assign the centroid Variables the appropriate\n",
    "        ##values\n",
    "        centroid_value = tf.placeholder(\"float64\", [dim])\n",
    "        cent_assigns = []\n",
    "        for centroid in centroids:\n",
    "            cent_assigns.append(tf.assign(centroid, centroid_value))\n",
    " \n",
    "        ##Variables for cluster assignments of individual vectors(initialized\n",
    "        ##to 0 at first)\n",
    "        assignments = [tf.Variable(0) for i in range(len(vectors))]\n",
    "        ##These nodes will assign an assignment Variable the appropriate\n",
    "        ##value\n",
    "        assignment_value = tf.placeholder(\"int32\")\n",
    "        cluster_assigns = []\n",
    "        for assignment in assignments:\n",
    "            cluster_assigns.append(tf.assign(assignment,\n",
    "                                             assignment_value))\n",
    " \n",
    "        ##Now lets construct the node that will compute the mean\n",
    "        #The placeholder for the input\n",
    "        mean_input = tf.placeholder(\"float\", [None, dim])\n",
    "        #The Node/op takes the input and computes a mean along the 0th\n",
    "        #dimension, i.e. the list of input vectors\n",
    "        mean_op = tf.reduce_mean(mean_input, 0)\n",
    " \n",
    "        ##Node for computing Euclidean distances\n",
    "        #Placeholders for input\n",
    "        v1 = tf.placeholder(\"float\", [dim])\n",
    "        v2 = tf.placeholder(\"float\", [dim])\n",
    "        euclid_dist = tf.sqrt(tf.reduce_sum(tf.pow(tf.sub(\n",
    "            v1, v2), 2)))\n",
    " \n",
    "        ##This node will figure out which cluster to assign a vector to,\n",
    "        ##based on Euclidean distances of the vector from the centroids.\n",
    "        #Placeholder for input\n",
    "        centroid_distances = tf.placeholder(\"float\", [noofclusters])\n",
    "        cluster_assignment = tf.argmin(centroid_distances, 0)\n",
    " \n",
    "        ##INITIALIZING STATE VARIABLES\n",
    " \n",
    "        ##This will help initialization of all Variables defined with respect\n",
    "        ##to the graph. The Variable-initializer should be defined after\n",
    "        ##all the Variables have been constructed, so that each of them\n",
    "        ##will be included in the initialization.\n",
    "        init_op = tf.initialize_all_variables()\n",
    " \n",
    "        #Initialize all variables\n",
    "        sess.run(init_op)\n",
    " \n",
    "        ##CLUSTERING ITERATIONS\n",
    " \n",
    "        #Now perform the Expectation-Maximization steps of K-Means clustering\n",
    "        #iterations. To keep things simple, we will only do a set number of\n",
    "        #iterations, instead of using a Stopping Criterion.\n",
    "        noofiterations = 100\n",
    "        for iteration_n in range(noofiterations):\n",
    " \n",
    "            ##EXPECTATION STEP\n",
    "            ##Based on the centroid locations till last iteration, compute\n",
    "            ##the _expected_ centroid assignments.\n",
    "            #Iterate over each vector\n",
    "            for vector_n in range(len(vectors)):\n",
    "                vect = vectors[vector_n]\n",
    "                #Compute Euclidean distance between this vector and each\n",
    "                #centroid. Remember that this list cannot be named\n",
    "                #'centroid_distances', since that is the input to the\n",
    "                #cluster assignment node.\n",
    "                distances = [sess.run(euclid_dist, feed_dict={\n",
    "                    v1: vect, v2: sess.run(centroid)})\n",
    "                             for centroid in centroids]\n",
    "                #Now use the cluster assignment node, with the distances\n",
    "                #as the input\n",
    "                assignment = sess.run(cluster_assignment, feed_dict = {\n",
    "                    centroid_distances: distances})\n",
    "                #Now assign the value to the appropriate state variable\n",
    "                sess.run(cluster_assigns[vector_n], feed_dict={\n",
    "                    assignment_value: assignment})\n",
    " \n",
    "            ##MAXIMIZATION STEP\n",
    "            #Based on the expected state computed from the Expectation Step,\n",
    "            #compute the locations of the centroids so as to maximize the\n",
    "            #overall objective of minimizing within-cluster Sum-of-Squares\n",
    "            for cluster_n in range(noofclusters):\n",
    "                #Collect all the vectors assigned to this cluster\n",
    "                assigned_vects = [vectors[i] for i in range(len(vectors))\n",
    "                                  if sess.run(assignments[i]) == cluster_n]\n",
    "                #Compute new centroid location\n",
    "                new_location = sess.run(mean_op, feed_dict={\n",
    "                    mean_input: array(assigned_vects)})\n",
    "                #Assign value to appropriate variable\n",
    "                sess.run(cent_assigns[cluster_n], feed_dict={\n",
    "                    centroid_value: new_location})\n",
    " \n",
    "        #Return centroids and assignments\n",
    "        centroids = sess.run(centroids)\n",
    "        assignments = sess.run(assignments)\n",
    "        return centroids, assignments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
